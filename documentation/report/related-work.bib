Automatically generated by Mendeley 1.1.2
Any changes to this file will be lost if it is regenerated by Mendeley.

@inproceedings{Jorda2007,
address = {New York, New York, USA},
author = {Jord\`{a}, Sergi and Geiger, G\"{u}nter and Alonso, Marcos and Kaltenbrunner, Martin},
booktitle = {Proceedings of the 1st international conference on Tangible and embedded interaction - TEI '07},
doi = {10.1145/1226969.1226998},
file = {:Users/Simon/Daten/Studium/Mendeley/2007/Jord\`{a} et al/Jord\`{a} et al. - 2007 - The reacTable.pdf:pdf},
isbn = {9781595936196},
keywords = {design,interaction techniques,musical instrument,musical performance,tabletop interfaces,tangible interfaces},
month = feb,
pages = {139},
publisher = {ACM Press},
title = {{The reacTable}},
url = {http://dl.acm.org/citation.cfm?id=1226969.1226998},
year = {2007}
}
@inproceedings{Cook:2001:PDC:1085152.1085154,
address = {Singapore, Singapore},
author = {Cook, Perry},
booktitle = {Proceedings of the 2001 conference on New interfaces for musical expression},
file = {:Users/Simon/Daten/Studium/Mendeley/2001/Cook/Cook - 2001 - Principles for designing computer music controllers(2).pdf:pdf},
keywords = {artistic interfaces,musical control},
pages = {1--4},
publisher = {National University of Singapore},
series = {NIME '01},
title = {{Principles for designing computer music controllers}},
url = {http://dl.acm.org/citation.cfm?id=1085152.1085154},
year = {2001}
}
@inproceedings{Miyama2010,
author = {Miyama, Chikashi},
booktitle = {NIME},
file = {:Users/Simon/Daten/Studium/Mendeley/2010/Miyama/Miyama - 2010 - Peacock A Non-haptic 3D Performance Interface.pdf:pdf},
keywords = {computer music,hardware and software design,musical interface,sensor technologies},
number = {Nime},
pages = {380--382},
title = {{Peacock : A Non-haptic 3D Performance Interface}},
url = {http://www.educ.dab.uts.edu.au/nime/PROCEEDINGS/papers/Demo O1-O20/P380\_Miyama.pdf},
year = {2010}
}
@article{Ullmer2000,
annote = {MVC like model: MCRpd        
not entirely conviced though},
author = {Ullmer, B. and Ishii, H.},
doi = {10.1147/sj.393.0915},
file = {:Users/Simon/Daten/Studium/Mendeley/2000/Ullmer, Ishii/Ullmer, Ishii - 2000 - Emerging frameworks for tangible user interfaces.pdf:pdf},
issn = {0018-8670},
journal = {IBM Systems Journal},
month = jul,
number = {3},
pages = {915--931},
title = {{Emerging frameworks for tangible user interfaces}},
url = {http://dl.acm.org/citation.cfm?id=1011416.1011452},
volume = {39},
year = {2000}
}
@book{Ishii1997,
address = {New York, New York, USA},
annote = {coined "tangible UI"
Tangible bits: Room, Desk, ...},
author = {Ishii, Hiroshi and Ullmer, Brygg},
booktitle = {Proceedings of the SIGCHI conference on Human factors in computing systems - CHI '97},
doi = {10.1145/258549.258715},
file = {:Users/Simon/Daten/Studium/Mendeley/1997/Ishii, Ullmer/Ishii, Ullmer - 1997 - Tangible bits.pdf:pdf},
isbn = {0897918029},
keywords = {ambient media,augmented reality,center and periphery,foreground and background,graspable user interface,tangible user interface,ubiquitous computing},
month = mar,
pages = {234--241},
publisher = {ACM Press},
title = {{Tangible bits}},
url = {http://dl.acm.org/citation.cfm?id=258549.258715},
year = {1997}
}
@article{Maki-Patola2005,
author = {M\"{a}ki-Patola, T and Laitinen, J and Kanerva, A and Takala, T},
file = {:Users/Simon/Daten/Studium/Mendeley/2005/M\"{a}ki-Patola et al/M\"{a}ki-Patola et al. - 2005 - Experiments with virtual reality instruments.pdf:pdf},
journal = {Virtual Reality},
keywords = {control mapping,gesture,musical instrument design,physical sound modeling,virtual instrument,widgets},
pages = {11--16},
publisher = {National University of Singapore},
title = {{Experiments with virtual reality instruments}},
url = {http://portal.acm.org/citation.cfm?id=1085939.1085946},
year = {2005}
}
@inproceedings{Dobrian2006,
abstract = {Is there a distinction between New Interfaces for Musical Expression and New Interfaces for Controlling Sound? This article begins with a brief overview of expression in musical performance, and examines some of the characteristics of effective “expressive” computer music instruments. It becomes apparent that sophisticated musical expression requires not only a good control interface but also virtuosic mastery of the instrument it controls. By studying effective acoustic instruments, choosing intuitive but complex gesture-sound mappings that take advantage of established instrumental skills, designing intelligent characterizations of performance gestures, and promoting long-term dedicated practice on a new interface, computer music instrument designers can enhance the expressive quality of computer music performance.},
annote = {"The lack of virtuosity on new musical interfaces is apparently another case of the “elephant in the corner”—a big bothersome issue that everyone knows is there but is hesitant to discuss."},
author = {Dobrian, Christopher and Koppelman, Daniel},
booktitle = {NIME},
file = {:Users/Simon/Daten/Studium/Mendeley/2006/Dobrian, Koppelman/Dobrian, Koppelman - 2006 - The E in NIME musical expression with new computer interfaces.pdf:pdf},
keywords = {expression,instrument design,performance,virtuosity},
pages = {277--282},
title = {{The E in NIME: musical expression with new computer interfaces}},
year = {2006}
}
@inproceedings{Hahnel2010,
author = {H\"{a}hnel, Tilo and Berndt, Axel},
booktitle = {NIME},
file = {:Users/Simon/Daten/Studium/Mendeley/2010/H\"{a}hnel, Berndt/H\"{a}hnel, Berndt - 2010 - Expressive articulation for synthetic music performances.pdf:pdf},
keywords = {articulation,expressive performance,historically informed},
number = {Nime},
pages = {277--282},
title = {{Expressive articulation for synthetic music performances}},
url = {http://isgwww.cs.uni-magdeburg.de/visual/files/publications/2010/Haehnel\_2010\_NIMEa.pdf},
year = {2010}
}
@article{Gamberini2011,
abstract = {This paper describes an issue-based method to evaluate the naturalness of an interface. The method consists of the execution of a series of tasks on that interface, which is subsequently systematically analyzed to identify breakdowns in the users’ actions. The systematic analysis of breakdowns is allowed by the support of video-coding software (The Observer by Noldus). This method is described on its theoretical bases and then applied to the evaluation of a natural interface, a walk-in-place locomotion system for virtual spaces called Superfeet. The procedure is comparative, since Superfeet is compared to two locomotion devices, Superfeet enhanced with headtracker and a more traditional Joypad. The test involves 36 participants (mean age = 23.68, SD = 3.14). The outcomes of the breakdown analysis are illustrated at a progressively finer level of granularity from the amount and length of breakdowns, to the circumstances of the breakdowns, to the type of actions involved in the breakdowns. The potential of this procedure for usability studies is finally synthesized.},
annote = {
        Action Breakdowns for quantitative studies},
author = {Gamberini, Luciano and Spagnolli, Anna and Prontu, Lisa and Furlan, Sarah and Martino, Francesco and Solaz, Beatriz Rey and Alca\~{n}iz, Mariano and Lozano, Jos\`{e} Antonio},
doi = {10.1007/s00779-011-0476-z},
file = {:Users/Simon/Daten/Studium/Mendeley/2011/Gamberini et al/Gamberini et al. - 2011 - How natural is a natural interface An evaluation procedure based on action breakdowns.pdf:pdf},
issn = {1617-4909},
journal = {Personal and Ubiquitous Computing},
keywords = {Computer Science},
month = oct,
pages = {1--11},
publisher = {Springer London},
title = {{How natural is a natural interface? An evaluation procedure based on action breakdowns}},
url = {http://www.springerlink.com/content/m8484ukn8rj43621/},
year = {2011}
}
@inproceedings{Gurevich2010,
annote = {terrible research, no point, but interesting question},
author = {Gurevich, Michael and Stapleton, Paul and Marquez-Borbon, Adnan},
booktitle = {NIME},
file = {:Users/Simon/Daten/Studium/Mendeley/2010/Gurevich, Stapleton, Marquez-Borbon/Gurevich, Stapleton, Marquez-Borbon - 2010 - Style and Constraint in Electronic Musical Instruments.pdf:pdf},
keywords = {design,interaction,performance,persuasive technology},
number = {Nime},
pages = {106--111},
title = {{Style and Constraint in Electronic Musical Instruments}},
year = {2010}
}
@inproceedings{Miller2010,
annote = {nicht revolution\"{a}r, aber eine neue Idee},
author = {Miller, Jace},
booktitle = {NIME},
file = {:Users/Simon/Daten/Studium/Mendeley/2010/Miller/Miller - 2010 - Wiiolin a virtual instrument using the Wii remote.pdf:pdf},
keywords = {cello,figure 1,gesture recognition,human computer interaction,motion,recognition,the orientation of the,violin,virtual instrument,wii remote,wii remote determines},
number = {June},
pages = {497ff},
title = {{Wiiolin: a virtual instrument using the Wii remote}},
url = {http://www.educ.dab.uts.edu.au/nime/PROCEEDINGS/papers/Demo Q1-Q15/P497\_Miller.pdf},
year = {2010}
}
@article{Kiefer2008,
author = {Kiefer, Chris},
file = {:Users/Simon/Daten/Studium/Mendeley/2008/Kiefer/Kiefer - 2008 - Evaluating the wiimote as a musical controller.pdf:pdf},
journal = {Proceedings of the International Computer Music Conference},
pages = {17--17},
title = {{Evaluating the wiimote as a musical controller}},
url = {http://ck13.net/wp-content/uploads/2010/10/wiimoteICMC08.pdf},
year = {2008}
}
@article{Fels2011,
author = {Fels, Sidney and Lyons, Michael},
file = {:Users/Simon/Daten/Studium/Mendeley/2011/Fels, Lyons/Fels, Lyons - 2011 - Siggraph 2011 Course Notes Advances in New Interfaces for Musical Expression.pdf:pdf},
journal = {Notes},
title = {{Siggraph 2011 Course Notes Advances in New Interfaces for Musical Expression}},
year = {2011}
}
@inproceedings{Lee2008a,
address = {New York, New York, USA},
author = {Lee, Hyun-Jean and Kim, Hyungsin and Gupta, Gaurav and Mazalek, Ali},
booktitle = {Proceedings of the 2nd international conference on Tangible and embedded interaction - TEI '08},
doi = {10.1145/1347390.1347400},
file = {:Users/Simon/Daten/Studium/Mendeley/2008/Lee et al/Lee et al. - 2008 - WiiArts.pdf:pdf},
isbn = {9781605580043},
keywords = {WiiRemotes,collaboration,creative and expressive art experiences,interactive video and sound,multi-user interaction},
month = feb,
pages = {33},
publisher = {ACM Press},
title = {{WiiArts}},
url = {http://dl.acm.org/citation.cfm?id=1347390.1347400},
year = {2008}
}
@inproceedings{Pedersen2011,
abstract = {We present interaction techniques for tangible tabletop in- terfaces that use active, motorized tangibles, what we call Tangible Bots. Tangible Bots can reflect changes in the digital model and assist users by haptic feedback, by cor- recting errors, by multi-touch control, and by allowing ef- ficient interaction with multiple tangibles. A first study shows that Tangible Bots are usable for fine-grained manipu- lation (e.g., rotating tangibles to a particular orientation); for coarse movements, Tangible Bots become useful only when several tangibles are controlled simultaneously. Participants prefer Tangible Bots and find them less taxing than passive, non-motorized tangibles. A second study focuses on use- fulness by studying how electronic musicians use Tangible Bots to create music with a tangible tabletop application. We conclude by discussing the further potential of active tangi- bles, and their relative benefits over passive tangibles and multi-touch.},
address = {New York, New York, USA},
author = {Pedersen, Esben Warming and Hornb\ae k, Kasper},
booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems - CHI '11},
doi = {10.1145/1978942.1979384},
file = {:Users/Simon/Daten/Studium/Mendeley/2011/Pedersen, Hornb\ae k/Pedersen, Hornb\ae k - 2011 - Tangible bots.pdf:pdf},
isbn = {9781450302289},
keywords = {active tangibles,bidirectional interfaces,tangible user interfaces,user evaluation},
month = may,
pages = {2975},
publisher = {ACM Press},
title = {{Tangible bots}},
url = {http://dl.acm.org/citation.cfm?id=1978942.1979384},
year = {2011}
}
@inproceedings{Pedersen2009,
abstract = {Tangible user interfaces for manipulating audio and music focus mostly on generating music on the spot, but rarely on how electronic musicians balance preparation and improvi- sation in staging live performances or on how the audience perceives the performances. We present mixiTUI, a tangi- ble sequencer that allows electronic musicians to import and perform electronic music. mixiTUI is developed in collab- oration with electronic musicians, with a focus on live ar- ranging, on visualizations of music, on tokens that represent key elements in live performances, and on how the audience experiences the tangible interface. We present an evaluation of mixiTUI in a concert with 117 participants and argue that mixiTUI improves both the audience’s and the musician’s experience.},
address = {New York, New York, USA},
annote = {Interviews mit Musikern},
author = {Pedersen, Esben Warming and Hornb\ae k, Kasper},
booktitle = {Proceedings of the 3rd International Conference on Tangible and Embedded Interaction - TEI '09},
doi = {10.1145/1517664.1517713},
file = {:Users/Simon/Daten/Studium/Mendeley/2009/Pedersen, Hornb\ae k/Pedersen, Hornb\ae k - 2009 - mixiTUI.pdf:pdf},
isbn = {9781605584935},
keywords = {evaluation,tangible sequencer,tangible user interface,user-centered design},
month = feb,
pages = {223},
publisher = {ACM Press},
title = {{mixiTUI}},
url = {http://dl.acm.org/citation.cfm?id=1517664.1517713},
year = {2009}
}
